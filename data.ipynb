{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the API key from the .env file\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"API key not found in the .env file. Please ensure it is set as OPENAI_API_KEY.\")\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", openai_api_key=api_key)\n",
    "\n",
    "print(\"Model initialized successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dhruv\\major project rag\\venv\\lib\\site-packages\\langchain_community\\document_loaders\\parsers\\pdf.py:322: UserWarning: Warning: Empty content on page 21 of document C:\\Users\\dhruv\\major project rag\\NS pdf (2).pdf\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyMuPDFLoader, UnstructuredURLLoader, YoutubeLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "import base64\n",
    "import httpx\n",
    "import re\n",
    "\n",
    "\n",
    "# Function to load data from PDFs\n",
    "def load_pdfs(file_paths):\n",
    "    documents = []\n",
    "    for file_path in file_paths:\n",
    "        loader = PyMuPDFLoader(file_path)\n",
    "        documents.extend(loader.load())\n",
    "    return documents\n",
    "\n",
    "\n",
    "# Function to load data from URLs\n",
    "def load_urls(urls):\n",
    "    documents = []  # Initialize the documents list\n",
    "    loader = UnstructuredURLLoader(urls=urls)\n",
    "    documents.extend(loader.load())\n",
    "    return documents\n",
    "\n",
    "\n",
    "# Function to load data from YouTube videos\n",
    "def load_youtube(video_urls):\n",
    "    documents = []  # Initialize the documents list\n",
    "    video_id_pattern = r\"(?:v=|\\/)([0-9A-Za-z_-]{11}).*\"\n",
    "    for video_url in video_urls:\n",
    "        match = re.search(video_id_pattern, video_url)\n",
    "        if match:\n",
    "            video_id = match.group(1)  # Extract video ID\n",
    "            loader = YoutubeLoader(video_id)  # Use video ID directly\n",
    "            documents.extend(loader.load())\n",
    "        else:\n",
    "            print(f\"Invalid YouTube URL: {video_url}\")\n",
    "    return documents\n",
    "\n",
    "\n",
    "# Function to process images\n",
    "def process_images(image_urls):\n",
    "    model = llm\n",
    "    documents = []  # Initialize the documents list\n",
    "    for image_url in image_urls:\n",
    "        # Encode image as base64\n",
    "        image_data = base64.b64encode(httpx.get(image_url).content).decode(\"utf-8\")\n",
    "        \n",
    "        # Create message for the model\n",
    "        message = HumanMessage(\n",
    "            content=[\n",
    "                {\"type\": \"text\", \"text\": \"Describe the content of this image. \"},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data}\"},\n",
    "                },\n",
    "            ],\n",
    "        )\n",
    "        \n",
    "        # Get response from the model\n",
    "        response = model.invoke([message])\n",
    "        documents.append(Document(page_content=response.content))\n",
    "    return documents\n",
    "\n",
    "\n",
    "# Function to load all types of data\n",
    "def load_all_data(pdf_paths, urls, youtube_links, image_urls):\n",
    "    pdf_docs = load_pdfs(pdf_paths)\n",
    "    url_docs = load_urls(urls)\n",
    "    youtube_docs = load_youtube(youtube_links)\n",
    "    image_docs = process_images(image_urls)\n",
    "    \n",
    "    all_documents = pdf_docs + url_docs + youtube_docs + image_docs\n",
    "    return all_documents\n",
    "\n",
    "\n",
    "# Example data inputs\n",
    "pdf_files = [\"pdf_files\"]\n",
    "web_urls = [\"web_urls\"]  # List of URLs\n",
    "youtube_videos = [\"youtube_videos_urls\"]  # YouTube links\n",
    "image_urls = [\"image_urls\"]  # URLs to images\n",
    "\n",
    "# Load data\n",
    "documents = load_all_data(pdf_files, web_urls, youtube_videos, image_urls)\n",
    "\n",
    "print(len(documents))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "welcome to this beginner tutorial on langra where we're going to cover the theory and then a practical example of how you can get stuck in so langra what is it why should you use it and how do you use it langra is an AI agent building framework built by Lang chain it's highly flexible and it allows you to connect language models together in a way that the llm can control what happens next it's supported in two major programming languages Python and JavaScript and it was released last October and since then it's been increasing in popularity as an alternative to other agent building Frameworks like crew aai and Microsoft autogen let's take a look at an example of how it might be used let's take a customer support agent who asks a question to an online website chatbot for a bank the chatbot agent might then look up the customer information it might then update the customer details based on the conversation and it might also then want to make a transaction for the customer but because this is a large transaction we might want verification from a real person before it goes ahead langra supports this with humanin the loop execution where the transaction can be authorized first before the conversation with the customer can continue what are some other applications where langra could be highly useful it could be useful for copywriting gathering information from across the internet and putting it together into a single article or report could be useful f for custom analytics for creating figures dashboards or extracting information from a database could be useful for customer service assistance so whether that's answering questions via email WhatsApp SMS or voice it could be useful for personalized recommendation as from previous interactions with the customer we might have an idea of what the customer prefers it could be useful for doing research to making sure that you stay up to date with the latest trends or any new articles that have been released and finally could be useful for personal marketing tailoring your Communications to each customer based on their personal characteristics so what are some features that make Lang graph particularly useful as an agentic framework it supports streaming straight out the box with either tokens or messages it also supports multiple execution at the same time or async execution it supports persistence with a database so that you don't need to persist your state between invocations and it also supports fault tolerant tool calls so that it can handle any failures with external apis as we've seen it supports human in the loop execution and because of the way it handles state it makes it quite easy to decide what the next actions should be let's take a look at the core building blocks of Lang graph that allow you to customize it for your use case let's take a look at the core building blocks for L graph nodes contain the code you want to execute and we connect them with edges which determine which node should be executed next we also have conditional edges and these can decide based on what's happened so far which node should be executed next and all of these components are tied together with the state which stores our inputs outputs and any variables that are created by to pass information between nodes let's see how all these components interact together in another example let's take another customer service agent who asks a question to our agent the input message is stored in our state which is also storing some custom information about that shop the opening hours our graph is then executed the state goes into the start of the graph and it is then passed to the first node where a call to a language model is made and a new message is added to the graph state after this the flow of execution moves to the end node and the final state is returned and we can return the output message to the user this is a very basic example but langra supports any architecture that you would like to build it includes architectures like a router where a conditional Edge chooses which prompt should be executed based on the input to the graph it supports a react agent where a language model can decide which tools should be executed we can execute those tools as code locally and the responses can be passed back into the language model for it to decide the next steps it also supports the reflection pattern which is where one language model is generating an output and another is reviewing that output and identifying any mistakes and passing feedback to the first to be able to correct them now that we've covered the theory let's take a look at how we can build these architectures in code if you're liking this video so far please like And subscribe as it'll motivate me to make more of this content first we're going to need to install the requirements if you've cloned the repository you can do this with Pip install d requirements if you haven't cloned the repository you can install the two packages Lang graph and Lang chain openai if you're following along you're also going to need an openai API key for this tutorial and you can get one of these by logging in to your open a account and going to platform. open.com we can then go to the API Keys Tab and click on create new secret key first we need to import all the classes and functions that we'll need for this tutorial we're then going to create our graph state where we store all of the inputs outputs and variables we're going to need to access during the graph execution we can then create our graph with this pre-built State graph class as this is a react agent we're going to need tools and this agent will only be doing one thing which is retrieving the weather at particular location so we can create a tool with the at tool decorator which is provided by Lang chain you don't need to use Lang chain but we're going to use it here for convenience I'm then creating a language model class with chat open Ai and putting in the API key that I retrieved earlier I'm then binding the tools that I've created the get weather function to this language model so the language model knows that this tool is available to use in order to provide these tools within the graph we need to create a node and we can do this with a pre-built node provided by Lang graph called tool node so we create that and then we're adding the node and naming it tool node to our existing graph now that we've got our tool we need the main entry node where we cool our language model to see if we need to perform any tool CS so I'm calling this prompt node and all that happens within this node is that we invoke our language model and we then add the response message into the graph state when we respond with messages and a list we then update the messages in the graph state with all of the new messages that have been returned this happens automatically and this is the way the state Works in langra to connect it up together we create a conditional Edge which depending on the output of the previous prompt node if there are any tool calls then we will send the execution to the tool node if there are no tool cools we're going to end the EXE execution then and return our response to the user we're also setting the entry point to our graph which connects the start node to our prompt node finally I'm then compiling the graph and then invoking it with what's the weather in Yorkshire and as expected we're getting out that the weather in New Yorkshire is currently cold and wet if you're interested in learning more I have another video on building a research agent if you really like this video I'd appreciate it if you liked and subscribed as it will motivate me to do more of this content thanks for watching have a good day\n"
     ]
    }
   ],
   "source": [
    "print(documents[83].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(documents)\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an intelligent assistant designed for answering questions \"\n",
    "    \"based on retrieved context. Carefully read the provided context and \"\n",
    "    \"use it exclusively to formulate your response. If the context does not \"\n",
    "    \"contain enough information to answer the question, explicitly state: \"\n",
    "    \"'I don't know based on the provided context.' \"\n",
    "    \"Your responses should be clear, relevant, and limited to three sentences \"\n",
    "    \"or fewer. Do not include information beyond the given context.\"\n",
    "    \"\\n\\n{context}\"\n",
    ")\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The different data types in Python include:\n",
      "\n",
      "- **Strings** (e.g., `\"python\"`)\n",
      "- **Numbers** (e.g., `10`, `15.5`)\n",
      "- **Lists** (e.g., `[\"python\", \"variables\"]`)\n",
      "- **Tuples** (e.g., `(\"python\", \"variables\")`)\n",
      "- **Dictionaries** (e.g., `{\"python\": \"variable\"}`)\n",
      "- **Sets** (e.g., `{1, 2, 3}`)\n",
      "- **Boolean** (e.g., `True`, `False`)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results = rag_chain.invoke({\"input\": \"what are different data types in python ?\"})\n",
    "print(results[\"answer\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
