{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the API key from the .env file\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"API key not found in the .env file. Please ensure it is set as OPENAI_API_KEY.\")\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", openai_api_key=api_key)\n",
    "\n",
    "print(\"Model initialized successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyMuPDFLoader, UnstructuredURLLoader, YoutubeLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "import base64\n",
    "import httpx\n",
    "import re\n",
    "\n",
    "\n",
    "# Function to load data from PDFs\n",
    "def load_pdfs(file_paths):\n",
    "    documents = []\n",
    "    for file_path in file_paths:\n",
    "        loader = PyMuPDFLoader(file_path)\n",
    "        documents.extend(loader.load())\n",
    "    return documents\n",
    "\n",
    "\n",
    "# Function to load data from URLs\n",
    "def load_urls(urls):\n",
    "    documents = []  # Initialize the documents list\n",
    "    loader = UnstructuredURLLoader(urls=urls)\n",
    "    documents.extend(loader.load())\n",
    "    return documents\n",
    "\n",
    "\n",
    "# Function to load data from YouTube videos\n",
    "def load_youtube(video_urls):\n",
    "    documents = []  # Initialize the documents list\n",
    "    video_id_pattern = r\"(?:v=|\\/)([0-9A-Za-z_-]{11}).*\"\n",
    "    for video_url in video_urls:\n",
    "        match = re.search(video_id_pattern, video_url)\n",
    "        if match:\n",
    "            video_id = match.group(1)  # Extract video ID\n",
    "            loader = YoutubeLoader(video_id)  # Use video ID directly\n",
    "            documents.extend(loader.load())\n",
    "        else:\n",
    "            print(f\"Invalid YouTube URL: {video_url}\")\n",
    "    return documents\n",
    "\n",
    "\n",
    "# Function to process images\n",
    "def process_images(image_urls):\n",
    "    model = llm\n",
    "    documents = []  # Initialize the documents list\n",
    "    for image_url in image_urls:\n",
    "        # Encode image as base64\n",
    "        image_data = base64.b64encode(httpx.get(image_url).content).decode(\"utf-8\")\n",
    "        \n",
    "        # Create message for the model\n",
    "        message = HumanMessage(\n",
    "            content=[\n",
    "                {\"type\": \"text\", \"text\": \"Describe the content of this image. \"},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data}\"},\n",
    "                },\n",
    "            ],\n",
    "        )\n",
    "        \n",
    "        # Get response from the model\n",
    "        response = model.invoke([message])\n",
    "        documents.append(Document(page_content=response.content))\n",
    "    return documents\n",
    "\n",
    "\n",
    "# Function to load all types of data\n",
    "def load_all_data(pdf_paths, urls, youtube_links, image_urls):\n",
    "    pdf_docs = load_pdfs(pdf_paths)\n",
    "    url_docs = load_urls(urls)\n",
    "    youtube_docs = load_youtube(youtube_links)\n",
    "    image_docs = process_images(image_urls)\n",
    "    \n",
    "    all_documents = pdf_docs + url_docs + youtube_docs + image_docs\n",
    "    return all_documents\n",
    "\n",
    "\n",
    "# Example data inputs\n",
    "pdf_files = [r\"C:\\Users\\dhruv\\Downloads\\CC_04 (1).pdf\"]\n",
    "web_urls = [\"https://www.w3schools.com/python/\"]  # List of URLs\n",
    "youtube_videos = [\"https://youtu.be/67_aMPDk2zw?si=mqjQoQTu40xfasM7\"]  # YouTube links\n",
    "image_urls=[\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRhmeXu7EIsaqIOuC3nxof9Rkj1xsK8EGJRR203k13OKG9zzRxT4eyDWpwBc9_Ydhq3yl0&usqp=CAU\"]\n",
    "# Load data\n",
    "documents = load_all_data(pdf_files, web_urls, youtube_videos, image_urls)\n",
    "\n",
    "print(len(documents))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(documents)\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=api_key)\n",
    "vectorstore = FAISS.from_documents(splits, embeddings)\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an intelligent assistant designed for answering questions \"\n",
    "    \"based on retrieved context. Carefully read the provided context and \"\n",
    "    \"use it exclusively to formulate your response. If the context does not \"\n",
    "    \"contain enough information to answer the question, explicitly state: \"\n",
    "    \"'I don't know based on the provided context.' \"\n",
    "    \"Your responses should be clear, relevant, and limited to three sentences \"\n",
    "    \"or fewer. Do not include information beyond the given context.\"\n",
    "    \"\\n\\n{context}\"\n",
    ")\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python is a popular programming language that can be used on a server to create web applications. It is known for its simplicity and versatility, making it a favored choice for many developers.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results = rag_chain.invoke({\"input\": \"What is python?\"})\n",
    "print(results[\"answer\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
